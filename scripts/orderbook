#!/bin/bash
#
# Retrieve order book data for a region and store it in a gzip'd snapshot file
#
# $1 - region ID
# $2 - assembly dir
# $3 - output dir
# $4 - tool dir

# Check a header file for an OK response
check_header() {
  test "$(head -1 ${1} | sed -e 's/^[[:space:]]*//g' -e 's/[[:space:]]*$//g')" == "HTTP/2 200"
}

# Get a page of order book data
get_page() {
  curl -s --compressed -X GET --header "Accept: application/json" -D header_$(printf %02d $2).txt \
       'https://esi.evetech.net/latest/markets/'$1'/orders/?datasource=tranquility&page='$2 > page_$(printf %02d $2).json
}

# Extra page count from header
get_total_pages() {
  echo $(cat ${1} | awk '/x-pages:/ { printf("%d",$2) }')
}

# Generate logging timestamp
stamp() {
    echo "$(date -u +'%Y%m%dT%H:%M:%S %Z')"
}

# Get now in milliseconds
get_now() {
    echo $(( $(date +"%s") * 1000 ))
}

# Setup area to receive pages
region=$1
now=$(( $(date +"%s") * 1000 ))
here=$(pwd)
snapfilename=region_${now}_$(date -u +"%Y%m%d")
assembly=$2/region_${region}_$$
output_dir=$3
tool_dir=$4
mkdir -p ${assembly}
trap "cd ${here} ; rm -rf ${assembly}" 0
cd ${assembly}

# Retrieve specified number of pages
done=0
page=1
start=$(get_now)
echo "$(stamp) Start retrieval for ${region}"
while [ ${done} -eq 0 ] ; do
    # Retrieve next page
    get_page ${region} ${page} 
    if ! check_header header_$(printf %02d ${page}).txt ; then
	# One second chance on error
	sleep 5
	get_page ${region} ${page} 
    fi

    # Quit on error
    if ! check_header header_$(printf %02d ${page}).txt ; then
	echo "error on page ${page}, exiting"
	echo "$(cat header_$(printf %02d ${page}).txt)"
	exit 1
    fi

    # Extract total page count and stop if we've received the last page
    max_pages=$(get_total_pages header_$(printf %02d ${page}).txt)
    if [ ${page} -ge ${max_pages} ] ; then
	done=1
    else
	page=$((${page} + 1))
    fi	
	

    # We're done if this page is empty
    #if [ $(jq 'length' page_$(printf %02d ${page}).json) -eq 0 ] ; then
    #	done=1
    #else
    #   page=$((${page} + 1))
    #fi	
done
end=$(get_now)
elapsed=$(( (${end} - ${start})/1000 ))
echo "$(stamp) Retrieval complete for ${region} in ${elapsed} seconds"

# Output order files to snapfile with format
#
# <order count>
# <order 1>
# <order 2>
# ...
mkdir -p ${output_dir}/regions/${region}
outfile=${assembly}/${snapfilename}
cat page_*.json | jq -c '.[]|[.type_id,.order_id,.is_buy_order,["\(.issued)"|fromdate * 1000],.price,.volume_total,.min_volume,.volume_remain,.range,.location_id,.duration]' | sed -e 's/\[//g' -e 's/\]//g' -e 's/^[[:space:]]*//g' -e 's/[[:space:]]*$//g' -e s'/"//g' | awk '{print '${region}'","$0}' >> ${outfile}
count=$(cat ${outfile} | wc -l | tr -d '[:blank:]')
echo -e "${count}\n$(cat ${outfile})" > ${outfile}
gzip ${outfile}
mv ${outfile}.gz ${output_dir}/regions/${region}
